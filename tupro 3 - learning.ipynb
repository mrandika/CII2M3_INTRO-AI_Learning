{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fk4LBeAG9KI"
      },
      "outputs": [],
      "source": [
        "# Depends on:\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "from collections import Counter\n",
        "\n",
        "# Benchmark\n",
        "import time\n",
        "\n",
        "# ⚠️ WARNING: Disable this if you're running locally (not on Google Colab)\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeYUqZAbG-q_"
      },
      "outputs": [],
      "source": [
        "def loadDataset(link: str, sheetName: str) -> pd.DataFrame:\n",
        "  return pd.read_excel(link, sheet_name=sheetName)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFvVD1xdXoUW"
      },
      "outputs": [],
      "source": [
        "def computeConfusionMatrix(actual, predicted):\n",
        "  matrix = {\n",
        "    'tp': 0,\n",
        "    'fp': 0,\n",
        "    'fn': 0,\n",
        "    'tn': 0\n",
        "  }\n",
        "\n",
        "  for i in range(len(actual)):\n",
        "    if actual[i] == 1 and predicted[i] == 1:\n",
        "      matrix['tp'] += 1\n",
        "    elif actual[i] == 0 and predicted[i] == 1:\n",
        "      matrix['fp'] += 1\n",
        "    elif actual[i] == 1 and predicted[i] == 0:\n",
        "      matrix['fn'] += 1\n",
        "    else:\n",
        "      matrix['tn'] += 1\n",
        "  \n",
        "  return matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getPerfomanceMatrix(actual, predicted):\n",
        "  matrix = computeConfusionMatrix(actual, predicted)\n",
        "\n",
        "  return {\n",
        "      'accuracy': ((matrix['tp'] + matrix['tn']) / (matrix['tp'] + matrix['fp'] + matrix['fn'] + matrix['tn'])) * 100.0,\n",
        "      'recall': ((matrix['tp']) / (matrix['tp'] + matrix['fn'])) * 100.0,\n",
        "      'precision': ((matrix['tp']) / (matrix['tp'] + matrix['fp'])) * 100.0\n",
        "  }"
      ],
      "metadata": {
        "id": "0goOtJfDB2ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOy7BSAzIyON"
      },
      "outputs": [],
      "source": [
        "def computeEuclidean(trainRow: list, testRow: list) -> float:\n",
        "  distance = 0.0\n",
        "\n",
        "  for i in range(len(trainRow) - 1):\n",
        "    distance += (trainRow[i] - testRow[i]) ** 2\n",
        "  \n",
        "  return math.sqrt(distance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvD_BRJCJQhm"
      },
      "outputs": [],
      "source": [
        "def getNeighbors(trainSet, testRow, numOfNeighbor: int) -> list:\n",
        "  distances = list()\n",
        "  neighbors = list()\n",
        "\n",
        "  for trainRow in trainSet:\n",
        "    distance = computeEuclidean(trainRow, testRow)\n",
        "    distances.append((trainRow, distance))\n",
        "\n",
        "  distances.sort(key=lambda tpl: tpl[1])\n",
        "\n",
        "  for i in range(numOfNeighbor):\n",
        "    neighbors.append(distances[i][0])\n",
        "\n",
        "  return neighbors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def neighborsVote(votes: list) -> int:\n",
        "  yes = 0\n",
        "  no = 0\n",
        "\n",
        "  for vote in votes:\n",
        "    if vote == 1:\n",
        "      yes += 1\n",
        "    else:\n",
        "      no += 1\n",
        "  \n",
        "  if yes >= no:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ],
      "metadata": {
        "id": "Bbysl11HxwUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXSabk_TKIvn"
      },
      "outputs": [],
      "source": [
        "def predictClassification(trainSet, testRow, numOfNeighbor: int) -> int:\n",
        "  neighbors = getNeighbors(trainSet, testRow, numOfNeighbor)\n",
        "  outputValues = [row[-1] for row in neighbors]\n",
        "  prediction = neighborsVote(outputValues)\n",
        "\n",
        "  return prediction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def crossValidation(dataset, numOfFolds):\n",
        "\tdatasetSplit = list()\n",
        "\tdatasetCopy = list(dataset)\n",
        "\tfoldSize = int(len(dataset) / numOfFolds)\n",
        " \n",
        "\tfor _ in range(numOfFolds):\n",
        "\t\tfold = list()\n",
        "  \n",
        "\t\twhile len(fold) < foldSize:\n",
        "\t\t\tindex = random.randrange(len(datasetCopy))\n",
        "\t\t\tfold.append(datasetCopy.pop(index))\n",
        "   \n",
        "\t\tdatasetSplit.append(fold)\n",
        "\treturn datasetSplit"
      ],
      "metadata": {
        "id": "FLKQlkzK_SoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(dataset, algorithm, numOfFolds, *args):\n",
        "\tfolds = crossValidation(dataset, numOfFolds)\n",
        "\tscores = list()\n",
        " \n",
        "\tfor fold in folds:\n",
        "\t\ttrainSet = list(folds)\n",
        "\t\ttrainSet.remove(fold)\n",
        "\t\ttrainSet = sum(trainSet, [])\n",
        "\t\ttestSet = list()\n",
        "  \n",
        "\t\tfor row in fold:\n",
        "\t\t\trow_copy = list(row)\n",
        "\t\t\ttestSet.append(row_copy)\n",
        "\t\t\trow_copy[-1] = None\n",
        "\n",
        "\t\tpredicted = algorithm(trainSet, testSet, *args)\n",
        "\t\tactual = [row[-1] for row in fold]\n",
        "\t\taccuracy = getPerfomanceMatrix(actual, predicted)['accuracy']\n",
        "\t\tscores.append(accuracy)\n",
        "  \n",
        "\treturn scores"
      ],
      "metadata": {
        "id": "DOfHjdBb_Uum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enAp96UqSuwX"
      },
      "outputs": [],
      "source": [
        "def knn(train, test, numOfNeighbor):\n",
        "  return [predictClassification(train, row, numOfNeighbor) for row in test]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def splitTrainAndEvaluation(dataset):\n",
        "  TRAIN_SET_PERCENTAGE = 0.9\n",
        "  VALIDATION_SET_PERCENTAGE = 1 - TRAIN_SET_PERCENTAGE\n",
        "\n",
        "  DATASET_COUNT = len(dataset)\n",
        "\n",
        "  TRAIN_SET_SIZE = math.floor(DATASET_COUNT*TRAIN_SET_PERCENTAGE)\n",
        "  VALIDATION_SET_SIZE = math.ceil(DATASET_COUNT*VALIDATION_SET_PERCENTAGE)\n",
        "\n",
        "  validationResult = dataset[0:VALIDATION_SET_SIZE]\n",
        "  trainSet = dataset[-TRAIN_SET_SIZE:]\n",
        "  \n",
        "  validationSet = [[value for value in row] for row in validationResult]\n",
        "\n",
        "  return trainSet, validationSet, [y[4] for y in validationResult]"
      ],
      "metadata": {
        "id": "rURGfcx6ltTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  print(\"Hello, mom!\")\n",
        "\n",
        "  start = time.time()\n",
        "\n",
        "  DATASET_URL = \"https://raw.githubusercontent.com/mrandika/CII2M3_INTRO-AI_Learning/main/traintest.xlsx\"\n",
        "  #DATASET_URL = \"/content/traintest.xlsx\"\n",
        "  N_FOLDS = 3\n",
        "  K_COUNT = 4\n",
        "\n",
        "  # Plain dataset\n",
        "  rawDataset = loadDataset(DATASET_URL, 'train').to_numpy()\n",
        "  dataset = [[value for value in row] for row in rawDataset]\n",
        "\n",
        "  # Get train and validation set\n",
        "  trainSet_dirty, validationSet_dirty, validationResult = splitTrainAndEvaluation(dataset)\n",
        "\n",
        "  # Cleansing, Remove ID column\n",
        "  trainSet = [row[-4:] for row in trainSet_dirty]\n",
        "  validationSet = [row[-4:] for row in validationSet_dirty]\n",
        "\n",
        "  # Learning Evaluation\n",
        "  scores = evaluate(trainSet, knn, N_FOLDS, K_COUNT)\n",
        "\n",
        "  print(\"\\n--- Train Set, Model Evaluation ---\")\n",
        "  print(f\"Data count:\", len(trainSet))\n",
        "  for i in range(N_FOLDS):\n",
        "    print(f\"Fold No.\", i+1, \"scores:\", scores[i])\n",
        "  print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))\n",
        "\n",
        "  # Validation\n",
        "  validationResults = knn(trainSet, validationSet, K_COUNT)\n",
        "  perfomanceMatrix = getPerfomanceMatrix(validationResult, validationResults)\n",
        "\n",
        "  print(\"\\n--- Validation Set ---\")\n",
        "  print(f\"Data count:\", len(validationSet))\n",
        "  for key, value in perfomanceMatrix.items():\n",
        "    print(\"{}: {}\".format(key, value), sep='')\n",
        "\n",
        "  print(\"{:<5} {:<5} {:<5} {:<5} {:<7} {:<7}\".format(\"ID\", \"x1\", \"x2\", \"x3\", \"Actual\", \"Expected\"))\n",
        "  for i in range(len(validationResults)):\n",
        "    print(\"{:<5} {:<5} {:<5} {:<5} {:<7} {:<7}\".format(validationSet_dirty[i][0], validationSet[i][0], validationSet[i][1], validationSet[i][2], validationResults[i], validationResult[i]))\n",
        "\n",
        "  # Test Set\n",
        "  testData = loadDataset(DATASET_URL, 'test')\n",
        "  testSet = [[value for value in row[-4:]] for row in testData.to_numpy()]\n",
        "  testResults = knn(trainSet, testSet, K_COUNT)\n",
        "\n",
        "  for i in range(len(testResults)):\n",
        "    testSet[i][3] = testResults[i]\n",
        "\n",
        "  print(\"\\n--- Test Set ---\")\n",
        "  print(f\"Data count:\", len(testSet))\n",
        "\n",
        "  print(\"{:<5} {:<5} {:<5} {:<5} {:<7}\".format(\"ID\", \"x1\", \"x2\", \"x3\", \"Given Label\"))\n",
        "  for i in range(len(testResults)):\n",
        "    print(\"{:<5} {:<5} {:<5} {:<5} {:<7}\".format(testData.to_numpy()[i][0], testSet[i][0], testSet[i][1], testSet[i][2], testSet[i][3]))\n",
        "\n",
        "  # Recap\n",
        "  results = [[testData.to_numpy()[i][0], testSet[i][0], testSet[i][1], testSet[i][2], testSet[i][3]] for i in range(len(testSet))]\n",
        "\n",
        "  resultDataFrame = pd.DataFrame(results, columns=[\"ID\", \"x1\", \"x2\", \"x3\", \"y\"])\n",
        "  resultDataFrame.to_excel('test_results.xlsx')\n",
        "\n",
        "  # ⚠️ WARNING: Disable this if you're running locally (not on Google Colab)\n",
        "  files.download('test_results.xlsx')\n",
        "\n",
        "  print(f\"\\nElapsed:\", time.time() - start)"
      ],
      "metadata": {
        "id": "i4vBlWv1jUzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_h13A_fqGYAH",
        "outputId": "1fe51614-952c-4ab4-f744-6b2c09d57be3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, mom!\n",
            "\n",
            "--- Train Set, Model Evaluation ---\n",
            "Data count: 200\n",
            "Fold No. 1 scores: 75.75757575757575\n",
            "Fold No. 2 scores: 81.81818181818183\n",
            "Fold No. 3 scores: 72.72727272727273\n",
            "Mean Accuracy: 76.768%\n",
            "\n",
            "--- Validation Set ---\n",
            "Data count: 30\n",
            "accuracy: 63.33333333333333\n",
            "recall: 76.19047619047619\n",
            "precision: 72.72727272727273\n",
            "ID    x1    x2    x3    Actual  Expected\n",
            "1     60    64    0     1       1      \n",
            "2     54    60    11    0       0      \n",
            "3     65    62    22    1       0      \n",
            "4     34    60    0     1       1      \n",
            "5     38    69    21    1       0      \n",
            "6     33    58    10    1       1      \n",
            "7     63    61    0     1       1      \n",
            "8     57    64    0     1       1      \n",
            "9     46    58    3     1       1      \n",
            "10    43    65    0     1       1      \n",
            "11    60    59    17    0       0      \n",
            "12    70    59    8     0       1      \n",
            "13    69    60    0     0       1      \n",
            "14    57    61    5     1       0      \n",
            "15    67    61    0     0       1      \n",
            "16    68    67    0     1       1      \n",
            "17    49    61    1     1       1      \n",
            "18    47    58    3     1       1      \n",
            "19    48    67    7     1       0      \n",
            "20    66    58    1     1       1      \n",
            "21    57    64    9     0       1      \n",
            "22    46    63    0     1       1      \n",
            "23    36    60    1     1       1      \n",
            "24    52    64    0     1       1      \n",
            "25    51    64    7     0       1      \n",
            "26    41    60    23    1       0      \n",
            "27    53    58    4     0       0      \n",
            "28    50    64    0     1       0      \n",
            "29    56    66    2     1       1      \n",
            "30    45    67    0     1       1      \n",
            "\n",
            "--- Test Set ---\n",
            "Data count: 10\n",
            "ID    x1    x2    x3    Given Label\n",
            "297   43    59    2     1      \n",
            "298   67    66    0     1      \n",
            "299   58    60    3     1      \n",
            "300   49    63    3     1      \n",
            "301   45    60    0     1      \n",
            "302   54    58    1     1      \n",
            "303   56    66    3     1      \n",
            "304   42    69    1     1      \n",
            "305   50    59    2     1      \n",
            "306   59    60    0     1      \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_00a8034b-ec8f-48b1-848c-45b14cdce1f3\", \"test_results.xlsx\", 5255)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Elapsed: 0.3223278522491455\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Tupro 3: Learning - KNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}